{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93b4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import (\n",
    "    get_embeddings, \n",
    "    synthesize_database, \n",
    "    synthesize_simple_database,\n",
    "    get_passenger_database,\n",
    "    check_passenger_exist,\n",
    "    create_simple_trainset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64fde6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_simple_data=True\n",
    "plan_number=None\n",
    "latency = 0.0\n",
    "message = \"Elapsed time for query based on privacy preserving is {} seconds\"\n",
    "\n",
    "# Airport dataset\n",
    "embed_original, indices = get_embeddings() # Considered the query pictures\n",
    "if is_simple_data:\n",
    "    embed_data, id_data, location_data = synthesize_simple_database(embed_original)\n",
    "    date_data = None\n",
    "else:\n",
    "    embed_data, id_data, date_data, location_data = synthesize_database(embed_original)\n",
    "\n",
    "embed_data = np.stack(embed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e59b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2222, 128)\n",
      "(2222,)\n"
     ]
    }
   ],
   "source": [
    "from global_variables import date_range, frequency_range\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = np.array(embed_data)\n",
    "print(x_train.shape)\n",
    "y_train = np.array(id_data)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "348989a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_softmax(logits: torch.Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "      logits: `[..., num_features]` unnormalized log probabilities\n",
    "      tau: non-negative scalar temperature\n",
    "      hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n",
    "            but will be differentiated as if it is the soft sample in autograd\n",
    "      dim (int): A dimension along which softmax will be computed. Default: -1.\n",
    "\n",
    "    Returns:\n",
    "      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n",
    "      If ``hard=True``, the returned samples will be one-hot, otherwise they will\n",
    "      be probability distributions that sum to 1 across `dim`.\n",
    "    \"\"\"\n",
    "    gumbels = (\n",
    "        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "    )  # ~Gumbel(0,1)\n",
    "\n",
    "    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
    "    y_soft = gumbels.softmax(dim)\n",
    "\n",
    "    if hard:\n",
    "        # Straight through.\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
    "        ret = y_hard - y_soft.detach() + y_soft\n",
    "    else:\n",
    "        # Reparametrization trick.\n",
    "        ret = y_soft\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f53aad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_mask(hidden_size_choices):\n",
    "    max_hidden_size = max(hidden_size_choices)\n",
    "    num_choices = len(hidden_size_choices)\n",
    "    masks = torch.zeros(max_hidden_size, num_choices)\n",
    "    for i in range(num_choices):\n",
    "        masks[:hidden_size_choices[i], i]=1\n",
    "    return masks\n",
    "    \n",
    "def get_flops_choices(input_size, hidden_size_choices, num_classes):\n",
    "    flops = []\n",
    "    for hidden_size in hidden_size_choices:\n",
    "        flops.append(2*hidden_size*input_size + 2*hidden_size*num_classes)\n",
    "    flops = np.array(flops)\n",
    "    return flops\n",
    "    \n",
    "class SuperNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_choices, num_classes):\n",
    "        super(SuperNet, self).__init__()\n",
    "        \n",
    "        max_hidden_size = max(hidden_size_choices)\n",
    "        num_choices = len(hidden_size_choices)\n",
    "        \n",
    "        self.arch_params = torch.nn.Parameter(torch.ones(num_choices), requires_grad=True)\n",
    "        self.masks = get_channel_mask(hidden_size_choices)\n",
    "        self.flops_choices = get_flops_choices(input_size, hidden_size_choices, num_classes)\n",
    "        self.flops_choices_normalized = torch.FloatTensor(self.flops_choices / np.max(self.flops_choices))\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, max_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(max_hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x, temperature):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        # print(self.arch_params)\n",
    "        gumbel_weights = gumbel_softmax(self.arch_params, tau=temperature, hard=False)\n",
    "        # print(gumbel_weights)\n",
    "        mask = torch.multiply(self.masks, gumbel_weights)\n",
    "        mask = torch.sum(mask, dim=-1)\n",
    "        out = torch.multiply(out, mask)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        flops_loss = self._get_flops_loss(gumbel_weights)\n",
    "        return out, flops_loss\n",
    "    \n",
    "    def _get_flops_loss(self, gumbel_weights):\n",
    "        return torch.matmul(self.flops_choices_normalized, gumbel_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c08d8",
   "metadata": {},
   "source": [
    "## flops_balance_factor = 0.5\n",
    "The trade-off parameter between performance (CE_Loss or MSE_Loss) and speed (Flops)\n",
    "\n",
    "Larger flops_balance_factor leads to a faster network with worse performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c70624ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/800], Overall_Loss: 4.1291, CE_Loss: 7.6995, Flops_Loss: 0.5588, Accuracy: 0.05%, Seleted Channel 100\n",
      "Epoch [20/800], Overall_Loss: 4.1269, CE_Loss: 7.6906, Flops_Loss: 0.5632, Accuracy: 0.09%, Seleted Channel 100\n",
      "Epoch [30/800], Overall_Loss: 4.1156, CE_Loss: 7.6903, Flops_Loss: 0.5409, Accuracy: 0.09%, Seleted Channel 450\n",
      "Epoch [40/800], Overall_Loss: 4.1162, CE_Loss: 7.6903, Flops_Loss: 0.5422, Accuracy: 0.09%, Seleted Channel 420\n",
      "Epoch [50/800], Overall_Loss: 4.1128, CE_Loss: 7.6811, Flops_Loss: 0.5445, Accuracy: 0.45%, Seleted Channel 420\n",
      "Epoch [60/800], Overall_Loss: 4.1062, CE_Loss: 7.6696, Flops_Loss: 0.5428, Accuracy: 0.99%, Seleted Channel 420\n",
      "Epoch [70/800], Overall_Loss: 4.1052, CE_Loss: 7.6684, Flops_Loss: 0.5420, Accuracy: 1.04%, Seleted Channel 170\n",
      "Epoch [80/800], Overall_Loss: 4.1035, CE_Loss: 7.6687, Flops_Loss: 0.5384, Accuracy: 0.99%, Seleted Channel 230\n",
      "Epoch [90/800], Overall_Loss: 4.0931, CE_Loss: 7.6577, Flops_Loss: 0.5285, Accuracy: 2.61%, Seleted Channel 230\n",
      "Epoch [100/800], Overall_Loss: 4.0861, CE_Loss: 7.6431, Flops_Loss: 0.5291, Accuracy: 5.67%, Seleted Channel 230\n",
      "Epoch [110/800], Overall_Loss: 4.0786, CE_Loss: 7.6435, Flops_Loss: 0.5138, Accuracy: 5.76%, Seleted Channel 230\n",
      "Epoch [120/800], Overall_Loss: 4.0834, CE_Loss: 7.6421, Flops_Loss: 0.5247, Accuracy: 6.48%, Seleted Channel 230\n",
      "Epoch [130/800], Overall_Loss: 4.0920, CE_Loss: 7.6224, Flops_Loss: 0.5616, Accuracy: 11.88%, Seleted Channel 230\n",
      "Epoch [140/800], Overall_Loss: 4.0748, CE_Loss: 7.6072, Flops_Loss: 0.5424, Accuracy: 21.47%, Seleted Channel 230\n",
      "Epoch [150/800], Overall_Loss: 4.0593, CE_Loss: 7.6118, Flops_Loss: 0.5067, Accuracy: 21.02%, Seleted Channel 120\n",
      "Epoch [160/800], Overall_Loss: 4.0582, CE_Loss: 7.6125, Flops_Loss: 0.5040, Accuracy: 21.38%, Seleted Channel 120\n",
      "Epoch [170/800], Overall_Loss: 4.0474, CE_Loss: 7.5976, Flops_Loss: 0.4972, Accuracy: 30.33%, Seleted Channel 120\n",
      "Epoch [180/800], Overall_Loss: 4.0432, CE_Loss: 7.5748, Flops_Loss: 0.5115, Accuracy: 46.67%, Seleted Channel 120\n",
      "Epoch [190/800], Overall_Loss: 4.0485, CE_Loss: 7.5687, Flops_Loss: 0.5283, Accuracy: 49.46%, Seleted Channel 120\n",
      "Epoch [200/800], Overall_Loss: 4.0387, CE_Loss: 7.5753, Flops_Loss: 0.5021, Accuracy: 47.70%, Seleted Channel 120\n",
      "Epoch [210/800], Overall_Loss: 4.0195, CE_Loss: 7.5645, Flops_Loss: 0.4744, Accuracy: 54.91%, Seleted Channel 120\n",
      "Epoch [220/800], Overall_Loss: 4.0092, CE_Loss: 7.5436, Flops_Loss: 0.4749, Accuracy: 64.54%, Seleted Channel 120\n",
      "Epoch [230/800], Overall_Loss: 4.0067, CE_Loss: 7.5427, Flops_Loss: 0.4706, Accuracy: 66.11%, Seleted Channel 120\n",
      "Epoch [240/800], Overall_Loss: 4.0028, CE_Loss: 7.5466, Flops_Loss: 0.4590, Accuracy: 64.18%, Seleted Channel 120\n",
      "Epoch [250/800], Overall_Loss: 3.9935, CE_Loss: 7.5265, Flops_Loss: 0.4604, Accuracy: 72.14%, Seleted Channel 120\n",
      "Epoch [260/800], Overall_Loss: 3.9859, CE_Loss: 7.4968, Flops_Loss: 0.4751, Accuracy: 80.11%, Seleted Channel 120\n",
      "Epoch [270/800], Overall_Loss: 3.9866, CE_Loss: 7.4917, Flops_Loss: 0.4814, Accuracy: 81.46%, Seleted Channel 120\n",
      "Epoch [280/800], Overall_Loss: 3.9801, CE_Loss: 7.5014, Flops_Loss: 0.4589, Accuracy: 79.75%, Seleted Channel 120\n",
      "Epoch [290/800], Overall_Loss: 3.9694, CE_Loss: 7.4787, Flops_Loss: 0.4602, Accuracy: 83.98%, Seleted Channel 120\n",
      "Epoch [300/800], Overall_Loss: 3.9560, CE_Loss: 7.4534, Flops_Loss: 0.4587, Accuracy: 85.82%, Seleted Channel 120\n",
      "Epoch [310/800], Overall_Loss: 3.9579, CE_Loss: 7.4446, Flops_Loss: 0.4713, Accuracy: 88.34%, Seleted Channel 120\n",
      "Epoch [320/800], Overall_Loss: 3.9528, CE_Loss: 7.4554, Flops_Loss: 0.4502, Accuracy: 86.77%, Seleted Channel 100\n",
      "Epoch [330/800], Overall_Loss: 3.9380, CE_Loss: 7.4378, Flops_Loss: 0.4382, Accuracy: 88.21%, Seleted Channel 100\n",
      "Epoch [340/800], Overall_Loss: 3.9233, CE_Loss: 7.4089, Flops_Loss: 0.4378, Accuracy: 88.93%, Seleted Channel 100\n",
      "Epoch [350/800], Overall_Loss: 3.9190, CE_Loss: 7.4235, Flops_Loss: 0.4145, Accuracy: 90.73%, Seleted Channel 280\n",
      "Epoch [360/800], Overall_Loss: 3.9254, CE_Loss: 7.4011, Flops_Loss: 0.4496, Accuracy: 91.36%, Seleted Channel 280\n",
      "Epoch [370/800], Overall_Loss: 3.9056, CE_Loss: 7.3973, Flops_Loss: 0.4140, Accuracy: 90.14%, Seleted Channel 280\n",
      "Epoch [380/800], Overall_Loss: 3.8938, CE_Loss: 7.3561, Flops_Loss: 0.4316, Accuracy: 93.07%, Seleted Channel 280\n",
      "Epoch [390/800], Overall_Loss: 3.8946, CE_Loss: 7.3368, Flops_Loss: 0.4523, Accuracy: 93.56%, Seleted Channel 100\n",
      "Epoch [400/800], Overall_Loss: 3.8904, CE_Loss: 7.3709, Flops_Loss: 0.4098, Accuracy: 93.02%, Seleted Channel 280\n",
      "Epoch [410/800], Overall_Loss: 3.8754, CE_Loss: 7.3356, Flops_Loss: 0.4152, Accuracy: 91.85%, Seleted Channel 280\n",
      "Epoch [420/800], Overall_Loss: 3.8555, CE_Loss: 7.3955, Flops_Loss: 0.3154, Accuracy: 85.73%, Seleted Channel 280\n",
      "Epoch [430/800], Overall_Loss: 3.8564, CE_Loss: 7.3437, Flops_Loss: 0.3692, Accuracy: 90.73%, Seleted Channel 100\n",
      "Epoch [440/800], Overall_Loss: 3.8580, CE_Loss: 7.3198, Flops_Loss: 0.3962, Accuracy: 92.53%, Seleted Channel 280\n",
      "Epoch [450/800], Overall_Loss: 3.8442, CE_Loss: 7.2928, Flops_Loss: 0.3955, Accuracy: 93.65%, Seleted Channel 280\n",
      "Epoch [460/800], Overall_Loss: 3.8278, CE_Loss: 7.2848, Flops_Loss: 0.3709, Accuracy: 93.11%, Seleted Channel 280\n",
      "Epoch [470/800], Overall_Loss: 3.8262, CE_Loss: 7.2497, Flops_Loss: 0.4027, Accuracy: 94.87%, Seleted Channel 280\n",
      "Epoch [480/800], Overall_Loss: 3.8251, CE_Loss: 7.2498, Flops_Loss: 0.4005, Accuracy: 94.42%, Seleted Channel 280\n",
      "Epoch [490/800], Overall_Loss: 3.8106, CE_Loss: 7.1983, Flops_Loss: 0.4228, Accuracy: 95.50%, Seleted Channel 280\n",
      "Epoch [500/800], Overall_Loss: 3.8008, CE_Loss: 7.2605, Flops_Loss: 0.3411, Accuracy: 94.91%, Seleted Channel 280\n",
      "Epoch [510/800], Overall_Loss: 3.7929, CE_Loss: 7.1919, Flops_Loss: 0.3939, Accuracy: 95.41%, Seleted Channel 280\n",
      "Epoch [520/800], Overall_Loss: 3.7967, CE_Loss: 7.2479, Flops_Loss: 0.3454, Accuracy: 94.06%, Seleted Channel 280\n",
      "Epoch [530/800], Overall_Loss: 3.7801, CE_Loss: 7.1943, Flops_Loss: 0.3660, Accuracy: 95.27%, Seleted Channel 280\n",
      "Epoch [540/800], Overall_Loss: 3.7552, CE_Loss: 7.0471, Flops_Loss: 0.4634, Accuracy: 96.94%, Seleted Channel 280\n",
      "Epoch [550/800], Overall_Loss: 3.7625, CE_Loss: 7.1662, Flops_Loss: 0.3589, Accuracy: 95.27%, Seleted Channel 420\n",
      "Epoch [560/800], Overall_Loss: 3.7516, CE_Loss: 7.0570, Flops_Loss: 0.4461, Accuracy: 96.31%, Seleted Channel 420\n",
      "Epoch [570/800], Overall_Loss: 3.7394, CE_Loss: 7.0713, Flops_Loss: 0.4075, Accuracy: 96.49%, Seleted Channel 420\n",
      "Epoch [580/800], Overall_Loss: 3.7333, CE_Loss: 7.1300, Flops_Loss: 0.3366, Accuracy: 94.78%, Seleted Channel 420\n",
      "Epoch [590/800], Overall_Loss: 3.7100, CE_Loss: 6.9856, Flops_Loss: 0.4344, Accuracy: 96.58%, Seleted Channel 400\n",
      "Epoch [600/800], Overall_Loss: 3.7163, CE_Loss: 7.0350, Flops_Loss: 0.3977, Accuracy: 96.04%, Seleted Channel 400\n",
      "Epoch [610/800], Overall_Loss: 3.7017, CE_Loss: 7.0132, Flops_Loss: 0.3902, Accuracy: 96.85%, Seleted Channel 400\n",
      "Epoch [620/800], Overall_Loss: 3.6948, CE_Loss: 7.0452, Flops_Loss: 0.3445, Accuracy: 95.99%, Seleted Channel 400\n",
      "Epoch [630/800], Overall_Loss: 3.6794, CE_Loss: 6.9710, Flops_Loss: 0.3879, Accuracy: 97.34%, Seleted Channel 400\n",
      "Epoch [640/800], Overall_Loss: 3.6702, CE_Loss: 6.9223, Flops_Loss: 0.4181, Accuracy: 97.25%, Seleted Channel 450\n",
      "Epoch [650/800], Overall_Loss: 3.6613, CE_Loss: 6.9288, Flops_Loss: 0.3938, Accuracy: 97.97%, Seleted Channel 450\n",
      "Epoch [660/800], Overall_Loss: 3.6390, CE_Loss: 6.8756, Flops_Loss: 0.4024, Accuracy: 98.33%, Seleted Channel 450\n",
      "Epoch [670/800], Overall_Loss: 3.6259, CE_Loss: 6.8553, Flops_Loss: 0.3965, Accuracy: 96.98%, Seleted Channel 450\n",
      "Epoch [680/800], Overall_Loss: 3.6196, CE_Loss: 6.8138, Flops_Loss: 0.4255, Accuracy: 97.66%, Seleted Channel 450\n",
      "Epoch [690/800], Overall_Loss: 3.6006, CE_Loss: 6.7721, Flops_Loss: 0.4292, Accuracy: 98.24%, Seleted Channel 450\n",
      "Epoch [700/800], Overall_Loss: 3.5801, CE_Loss: 6.7313, Flops_Loss: 0.4289, Accuracy: 98.65%, Seleted Channel 450\n",
      "Epoch [710/800], Overall_Loss: 3.5724, CE_Loss: 6.7302, Flops_Loss: 0.4145, Accuracy: 97.97%, Seleted Channel 450\n",
      "Epoch [720/800], Overall_Loss: 3.5764, CE_Loss: 6.7470, Flops_Loss: 0.4057, Accuracy: 97.88%, Seleted Channel 450\n",
      "Epoch [730/800], Overall_Loss: 3.5428, CE_Loss: 6.6444, Flops_Loss: 0.4413, Accuracy: 98.56%, Seleted Channel 450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [740/800], Overall_Loss: 3.5228, CE_Loss: 6.6329, Flops_Loss: 0.4127, Accuracy: 98.42%, Seleted Channel 450\n",
      "Epoch [750/800], Overall_Loss: 3.5090, CE_Loss: 6.5703, Flops_Loss: 0.4476, Accuracy: 98.65%, Seleted Channel 450\n",
      "Epoch [760/800], Overall_Loss: 3.4997, CE_Loss: 6.5416, Flops_Loss: 0.4578, Accuracy: 98.60%, Seleted Channel 450\n",
      "Epoch [770/800], Overall_Loss: 3.4850, CE_Loss: 6.5267, Flops_Loss: 0.4432, Accuracy: 98.74%, Seleted Channel 450\n",
      "Epoch [780/800], Overall_Loss: 3.4698, CE_Loss: 6.5141, Flops_Loss: 0.4255, Accuracy: 98.83%, Seleted Channel 450\n",
      "Epoch [790/800], Overall_Loss: 3.4451, CE_Loss: 6.4259, Flops_Loss: 0.4643, Accuracy: 98.96%, Seleted Channel 450\n",
      "Epoch [800/800], Overall_Loss: 3.4573, CE_Loss: 6.4906, Flops_Loss: 0.4239, Accuracy: 98.56%, Seleted Channel 450\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the neural network\n",
    "in_dim = x_train.shape[1]\n",
    "hidden_size_choices = list(range(100,1000,10))\n",
    "num_classes =  x_train.shape[0]\n",
    "net = SuperNet(in_dim, hidden_size_choices, num_classes)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net_weight_lr = 0.0001\n",
    "arch_lr = 0.01\n",
    "\n",
    "optimizer_net = optim.Adam([p for name, p in net.named_parameters() if 'arch' not in name], lr=net_weight_lr)\n",
    "optimizer_arch = optim.Adam([p for name, p in net.named_parameters() if 'arch' in name], lr=arch_lr)\n",
    "\n",
    "# Search Epoch\n",
    "num_epochs = 800\n",
    "\n",
    "# Iteartively optimize architecture parameters and network weights every 'search_freq' epochs\n",
    "search_freq = 20\n",
    "\n",
    "# The factor to balance performance (CE Loss or MSE Loss) and FLOPs\n",
    "# Larger flops_balance_factor leads to a faster network with worse performance\n",
    "flops_balance_factor = 0.5 \n",
    "\n",
    "# The tempreature is decayed by 'temp_anneal_factor' every 'temp_anneal_freq' epochs\n",
    "# Larger temp leads to a gumbel weight that is more close to 1-hot distribution  \n",
    "temp = 5\n",
    "temp_anneal_factor = 0.95\n",
    "temp_anneal_freq = num_epochs/25 # The temperatur will decay 25 times during the search\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % temp_anneal_freq == 0:\n",
    "        temp = temp * temp_anneal_factor\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, flops_loss = net(x_train, temp)\n",
    "    CE_loss = criterion(outputs, y_train)\n",
    "    loss = (1 - flops_balance_factor) * CE_loss + flops_balance_factor * flops_loss\n",
    "    \n",
    "    if int(epoch/search_freq)%2==0:\n",
    "        optimizer_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_net.step()\n",
    "    else:\n",
    "        optimizer_arch.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_arch.step()\n",
    "    \n",
    "    selected_channel_id = np.argmax(net.arch_params.data.numpy())\n",
    "    selected_channel = hidden_size_choices[selected_channel_id]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total = y_train.size(0)\n",
    "        correct = (predicted == y_train).sum().item()\n",
    "        accuracy = correct / total\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            \n",
    "            print('Epoch [{}/{}], Overall_Loss: {:.4f}, CE_Loss: {:.4f}, Flops_Loss: {:.4f}, Accuracy: {:.2f}%, Seleted Channel {}'\n",
    "                  .format(epoch+1, num_epochs, loss.item(), CE_loss.item(),\n",
    "                          flops_loss.item(), accuracy * 100, selected_channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255261b",
   "metadata": {},
   "source": [
    "## flops_balance_factor = 0.8\n",
    "The trade-off parameter between performance (CE_Loss or MSE_Loss) and speed (Flops)\n",
    "\n",
    "Larger flops_balance_factor leads to a faster network with worse performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "240ecac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Overall_Loss: 1.9738, CE_Loss: 7.7000, Flops_Loss: 0.5423, Accuracy: 0.14%, Seleted Channel 100\n",
      "Epoch [20/1000], Overall_Loss: 1.9717, CE_Loss: 7.6919, Flops_Loss: 0.5417, Accuracy: 0.23%, Seleted Channel 100\n",
      "Epoch [30/1000], Overall_Loss: 1.9773, CE_Loss: 7.6909, Flops_Loss: 0.5489, Accuracy: 0.23%, Seleted Channel 330\n",
      "Epoch [40/1000], Overall_Loss: 1.9776, CE_Loss: 7.6908, Flops_Loss: 0.5493, Accuracy: 0.23%, Seleted Channel 340\n",
      "Epoch [50/1000], Overall_Loss: 1.9689, CE_Loss: 7.6825, Flops_Loss: 0.5405, Accuracy: 0.81%, Seleted Channel 340\n",
      "Epoch [60/1000], Overall_Loss: 1.9890, CE_Loss: 7.6695, Flops_Loss: 0.5689, Accuracy: 2.30%, Seleted Channel 340\n",
      "Epoch [70/1000], Overall_Loss: 1.9669, CE_Loss: 7.6700, Flops_Loss: 0.5411, Accuracy: 2.52%, Seleted Channel 130\n",
      "Epoch [80/1000], Overall_Loss: 1.9578, CE_Loss: 7.6708, Flops_Loss: 0.5295, Accuracy: 2.39%, Seleted Channel 210\n",
      "Epoch [90/1000], Overall_Loss: 1.9552, CE_Loss: 7.6593, Flops_Loss: 0.5292, Accuracy: 3.47%, Seleted Channel 210\n",
      "Epoch [100/1000], Overall_Loss: 1.9457, CE_Loss: 7.6459, Flops_Loss: 0.5207, Accuracy: 7.20%, Seleted Channel 210\n",
      "Epoch [110/1000], Overall_Loss: 1.9490, CE_Loss: 7.6438, Flops_Loss: 0.5253, Accuracy: 7.97%, Seleted Channel 130\n",
      "Epoch [120/1000], Overall_Loss: 1.9381, CE_Loss: 7.6454, Flops_Loss: 0.5113, Accuracy: 7.52%, Seleted Channel 130\n",
      "Epoch [130/1000], Overall_Loss: 1.9263, CE_Loss: 7.6332, Flops_Loss: 0.4996, Accuracy: 13.19%, Seleted Channel 130\n",
      "Epoch [140/1000], Overall_Loss: 1.9411, CE_Loss: 7.6126, Flops_Loss: 0.5232, Accuracy: 22.46%, Seleted Channel 130\n",
      "Epoch [150/1000], Overall_Loss: 1.9299, CE_Loss: 7.6133, Flops_Loss: 0.5090, Accuracy: 21.74%, Seleted Channel 130\n",
      "Epoch [160/1000], Overall_Loss: 1.9361, CE_Loss: 7.6119, Flops_Loss: 0.5171, Accuracy: 22.77%, Seleted Channel 180\n",
      "Epoch [170/1000], Overall_Loss: 1.9165, CE_Loss: 7.5996, Flops_Loss: 0.4957, Accuracy: 32.22%, Seleted Channel 180\n",
      "Epoch [180/1000], Overall_Loss: 1.9229, CE_Loss: 7.5772, Flops_Loss: 0.5093, Accuracy: 47.39%, Seleted Channel 180\n",
      "Epoch [190/1000], Overall_Loss: 1.9113, CE_Loss: 7.5787, Flops_Loss: 0.4944, Accuracy: 47.07%, Seleted Channel 230\n",
      "Epoch [200/1000], Overall_Loss: 1.9331, CE_Loss: 7.5715, Flops_Loss: 0.5235, Accuracy: 49.68%, Seleted Channel 230\n",
      "Epoch [210/1000], Overall_Loss: 1.9046, CE_Loss: 7.5612, Flops_Loss: 0.4905, Accuracy: 56.35%, Seleted Channel 230\n",
      "Epoch [220/1000], Overall_Loss: 1.9039, CE_Loss: 7.5379, Flops_Loss: 0.4954, Accuracy: 67.10%, Seleted Channel 230\n",
      "Epoch [230/1000], Overall_Loss: 1.8970, CE_Loss: 7.5384, Flops_Loss: 0.4867, Accuracy: 67.60%, Seleted Channel 230\n",
      "Epoch [240/1000], Overall_Loss: 1.8987, CE_Loss: 7.5377, Flops_Loss: 0.4889, Accuracy: 67.78%, Seleted Channel 150\n",
      "Epoch [250/1000], Overall_Loss: 1.8868, CE_Loss: 7.5206, Flops_Loss: 0.4783, Accuracy: 73.36%, Seleted Channel 150\n",
      "Epoch [260/1000], Overall_Loss: 1.8903, CE_Loss: 7.4916, Flops_Loss: 0.4900, Accuracy: 80.42%, Seleted Channel 150\n",
      "Epoch [270/1000], Overall_Loss: 1.8737, CE_Loss: 7.4986, Flops_Loss: 0.4674, Accuracy: 79.66%, Seleted Channel 230\n",
      "Epoch [280/1000], Overall_Loss: 1.8821, CE_Loss: 7.4937, Flops_Loss: 0.4792, Accuracy: 80.47%, Seleted Channel 230\n",
      "Epoch [290/1000], Overall_Loss: 1.8709, CE_Loss: 7.4744, Flops_Loss: 0.4700, Accuracy: 84.38%, Seleted Channel 230\n",
      "Epoch [300/1000], Overall_Loss: 1.8652, CE_Loss: 7.4476, Flops_Loss: 0.4697, Accuracy: 87.44%, Seleted Channel 230\n",
      "Epoch [310/1000], Overall_Loss: 1.8462, CE_Loss: 7.4586, Flops_Loss: 0.4431, Accuracy: 86.14%, Seleted Channel 150\n",
      "Epoch [320/1000], Overall_Loss: 1.8484, CE_Loss: 7.4569, Flops_Loss: 0.4463, Accuracy: 86.63%, Seleted Channel 150\n",
      "Epoch [330/1000], Overall_Loss: 1.8441, CE_Loss: 7.4319, Flops_Loss: 0.4472, Accuracy: 88.43%, Seleted Channel 150\n",
      "Epoch [340/1000], Overall_Loss: 1.8278, CE_Loss: 7.4134, Flops_Loss: 0.4314, Accuracy: 89.42%, Seleted Channel 150\n",
      "Epoch [350/1000], Overall_Loss: 1.8252, CE_Loss: 7.4125, Flops_Loss: 0.4283, Accuracy: 89.83%, Seleted Channel 150\n",
      "Epoch [360/1000], Overall_Loss: 1.8262, CE_Loss: 7.4116, Flops_Loss: 0.4299, Accuracy: 89.92%, Seleted Channel 150\n",
      "Epoch [370/1000], Overall_Loss: 1.8238, CE_Loss: 7.3820, Flops_Loss: 0.4343, Accuracy: 90.55%, Seleted Channel 150\n",
      "Epoch [380/1000], Overall_Loss: 1.8089, CE_Loss: 7.3637, Flops_Loss: 0.4202, Accuracy: 92.44%, Seleted Channel 150\n",
      "Epoch [390/1000], Overall_Loss: 1.8158, CE_Loss: 7.3509, Flops_Loss: 0.4320, Accuracy: 92.17%, Seleted Channel 150\n",
      "Epoch [400/1000], Overall_Loss: 1.7951, CE_Loss: 7.3756, Flops_Loss: 0.3999, Accuracy: 91.09%, Seleted Channel 150\n",
      "Epoch [410/1000], Overall_Loss: 1.7960, CE_Loss: 7.3418, Flops_Loss: 0.4095, Accuracy: 92.93%, Seleted Channel 150\n",
      "Epoch [420/1000], Overall_Loss: 1.7989, CE_Loss: 7.2974, Flops_Loss: 0.4243, Accuracy: 93.79%, Seleted Channel 150\n",
      "Epoch [430/1000], Overall_Loss: 1.7716, CE_Loss: 7.3320, Flops_Loss: 0.3815, Accuracy: 92.21%, Seleted Channel 150\n",
      "Epoch [440/1000], Overall_Loss: 1.7783, CE_Loss: 7.3236, Flops_Loss: 0.3920, Accuracy: 93.07%, Seleted Channel 150\n",
      "Epoch [450/1000], Overall_Loss: 1.7681, CE_Loss: 7.3012, Flops_Loss: 0.3848, Accuracy: 93.11%, Seleted Channel 150\n",
      "Epoch [460/1000], Overall_Loss: 1.7521, CE_Loss: 7.2898, Flops_Loss: 0.3677, Accuracy: 92.80%, Seleted Channel 150\n",
      "Epoch [470/1000], Overall_Loss: 1.7361, CE_Loss: 7.3108, Flops_Loss: 0.3424, Accuracy: 91.40%, Seleted Channel 150\n",
      "Epoch [480/1000], Overall_Loss: 1.7400, CE_Loss: 7.3027, Flops_Loss: 0.3493, Accuracy: 91.99%, Seleted Channel 150\n",
      "Epoch [490/1000], Overall_Loss: 1.7426, CE_Loss: 7.2610, Flops_Loss: 0.3630, Accuracy: 93.16%, Seleted Channel 150\n",
      "Epoch [500/1000], Overall_Loss: 1.7356, CE_Loss: 7.2297, Flops_Loss: 0.3621, Accuracy: 93.38%, Seleted Channel 150\n",
      "Epoch [510/1000], Overall_Loss: 1.7341, CE_Loss: 7.2310, Flops_Loss: 0.3598, Accuracy: 93.61%, Seleted Channel 150\n",
      "Epoch [520/1000], Overall_Loss: 1.7395, CE_Loss: 7.2220, Flops_Loss: 0.3689, Accuracy: 93.83%, Seleted Channel 150\n",
      "Epoch [530/1000], Overall_Loss: 1.7182, CE_Loss: 7.2277, Flops_Loss: 0.3409, Accuracy: 93.65%, Seleted Channel 150\n",
      "Epoch [540/1000], Overall_Loss: 1.7081, CE_Loss: 7.1994, Flops_Loss: 0.3353, Accuracy: 93.11%, Seleted Channel 150\n",
      "Epoch [550/1000], Overall_Loss: 1.7198, CE_Loss: 7.1708, Flops_Loss: 0.3570, Accuracy: 93.83%, Seleted Channel 150\n",
      "Epoch [560/1000], Overall_Loss: 1.7162, CE_Loss: 7.1775, Flops_Loss: 0.3509, Accuracy: 93.61%, Seleted Channel 150\n",
      "Epoch [570/1000], Overall_Loss: 1.6900, CE_Loss: 7.1991, Flops_Loss: 0.3127, Accuracy: 91.85%, Seleted Channel 150\n",
      "Epoch [580/1000], Overall_Loss: 1.7028, CE_Loss: 7.1151, Flops_Loss: 0.3497, Accuracy: 93.79%, Seleted Channel 150\n",
      "Epoch [590/1000], Overall_Loss: 1.6735, CE_Loss: 7.1881, Flops_Loss: 0.2949, Accuracy: 87.13%, Seleted Channel 150\n",
      "Epoch [600/1000], Overall_Loss: 1.6876, CE_Loss: 7.1443, Flops_Loss: 0.3234, Accuracy: 91.90%, Seleted Channel 150\n",
      "Epoch [610/1000], Overall_Loss: 1.6780, CE_Loss: 7.1366, Flops_Loss: 0.3134, Accuracy: 93.20%, Seleted Channel 150\n",
      "Epoch [620/1000], Overall_Loss: 1.6687, CE_Loss: 7.1196, Flops_Loss: 0.3060, Accuracy: 93.43%, Seleted Channel 150\n",
      "Epoch [630/1000], Overall_Loss: 1.6588, CE_Loss: 7.1436, Flops_Loss: 0.2877, Accuracy: 91.90%, Seleted Channel 150\n",
      "Epoch [640/1000], Overall_Loss: 1.6599, CE_Loss: 7.1401, Flops_Loss: 0.2899, Accuracy: 92.26%, Seleted Channel 150\n",
      "Epoch [650/1000], Overall_Loss: 1.6566, CE_Loss: 7.1089, Flops_Loss: 0.2935, Accuracy: 92.93%, Seleted Channel 150\n",
      "Epoch [660/1000], Overall_Loss: 1.6420, CE_Loss: 7.0916, Flops_Loss: 0.2796, Accuracy: 90.37%, Seleted Channel 150\n",
      "Epoch [670/1000], Overall_Loss: 1.6663, CE_Loss: 7.0261, Flops_Loss: 0.3264, Accuracy: 94.55%, Seleted Channel 120\n",
      "Epoch [680/1000], Overall_Loss: 1.6602, CE_Loss: 7.0372, Flops_Loss: 0.3160, Accuracy: 93.79%, Seleted Channel 120\n",
      "Epoch [690/1000], Overall_Loss: 1.6432, CE_Loss: 7.0463, Flops_Loss: 0.2924, Accuracy: 93.20%, Seleted Channel 120\n",
      "Epoch [700/1000], Overall_Loss: 1.6327, CE_Loss: 7.0447, Flops_Loss: 0.2798, Accuracy: 94.06%, Seleted Channel 120\n",
      "Epoch [710/1000], Overall_Loss: 1.6185, CE_Loss: 7.0871, Flops_Loss: 0.2514, Accuracy: 89.38%, Seleted Channel 120\n",
      "Epoch [720/1000], Overall_Loss: 1.6175, CE_Loss: 7.0860, Flops_Loss: 0.2504, Accuracy: 88.39%, Seleted Channel 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [730/1000], Overall_Loss: 1.6053, CE_Loss: 7.0879, Flops_Loss: 0.2346, Accuracy: 85.96%, Seleted Channel 120\n",
      "Epoch [740/1000], Overall_Loss: 1.6330, CE_Loss: 6.9114, Flops_Loss: 0.3134, Accuracy: 94.28%, Seleted Channel 120\n",
      "Epoch [750/1000], Overall_Loss: 1.6100, CE_Loss: 7.0205, Flops_Loss: 0.2574, Accuracy: 93.61%, Seleted Channel 120\n",
      "Epoch [760/1000], Overall_Loss: 1.5969, CE_Loss: 7.0751, Flops_Loss: 0.2274, Accuracy: 88.34%, Seleted Channel 120\n",
      "Epoch [770/1000], Overall_Loss: 1.5904, CE_Loss: 7.0998, Flops_Loss: 0.2131, Accuracy: 91.18%, Seleted Channel 120\n",
      "Epoch [780/1000], Overall_Loss: 1.6023, CE_Loss: 6.9293, Flops_Loss: 0.2705, Accuracy: 93.25%, Seleted Channel 120\n",
      "Epoch [790/1000], Overall_Loss: 1.5916, CE_Loss: 6.9875, Flops_Loss: 0.2426, Accuracy: 92.53%, Seleted Channel 120\n",
      "Epoch [800/1000], Overall_Loss: 1.5849, CE_Loss: 7.0581, Flops_Loss: 0.2166, Accuracy: 91.72%, Seleted Channel 120\n",
      "Epoch [810/1000], Overall_Loss: 1.5911, CE_Loss: 6.9281, Flops_Loss: 0.2569, Accuracy: 93.20%, Seleted Channel 120\n",
      "Epoch [820/1000], Overall_Loss: 1.5865, CE_Loss: 6.8547, Flops_Loss: 0.2695, Accuracy: 92.89%, Seleted Channel 120\n",
      "Epoch [830/1000], Overall_Loss: 1.5835, CE_Loss: 6.9185, Flops_Loss: 0.2497, Accuracy: 94.28%, Seleted Channel 120\n",
      "Epoch [840/1000], Overall_Loss: 1.5823, CE_Loss: 6.9051, Flops_Loss: 0.2515, Accuracy: 93.79%, Seleted Channel 120\n",
      "Epoch [850/1000], Overall_Loss: 1.5618, CE_Loss: 6.9972, Flops_Loss: 0.2030, Accuracy: 90.01%, Seleted Channel 120\n",
      "Epoch [860/1000], Overall_Loss: 1.5606, CE_Loss: 6.9331, Flops_Loss: 0.2175, Accuracy: 92.17%, Seleted Channel 120\n",
      "Epoch [870/1000], Overall_Loss: 1.5601, CE_Loss: 6.9485, Flops_Loss: 0.2130, Accuracy: 93.47%, Seleted Channel 120\n",
      "Epoch [880/1000], Overall_Loss: 1.5645, CE_Loss: 6.9006, Flops_Loss: 0.2305, Accuracy: 93.52%, Seleted Channel 120\n",
      "Epoch [890/1000], Overall_Loss: 1.5505, CE_Loss: 6.9521, Flops_Loss: 0.2001, Accuracy: 90.01%, Seleted Channel 120\n",
      "Epoch [900/1000], Overall_Loss: 1.5359, CE_Loss: 7.0288, Flops_Loss: 0.1627, Accuracy: 70.57%, Seleted Channel 120\n",
      "Epoch [910/1000], Overall_Loss: 1.5434, CE_Loss: 6.9207, Flops_Loss: 0.1991, Accuracy: 89.29%, Seleted Channel 120\n",
      "Epoch [920/1000], Overall_Loss: 1.5476, CE_Loss: 6.8636, Flops_Loss: 0.2186, Accuracy: 93.11%, Seleted Channel 120\n",
      "Epoch [930/1000], Overall_Loss: 1.5408, CE_Loss: 6.8352, Flops_Loss: 0.2172, Accuracy: 93.11%, Seleted Channel 120\n",
      "Epoch [940/1000], Overall_Loss: 1.5307, CE_Loss: 6.8931, Flops_Loss: 0.1902, Accuracy: 87.80%, Seleted Channel 120\n",
      "Epoch [950/1000], Overall_Loss: 1.5341, CE_Loss: 6.8266, Flops_Loss: 0.2110, Accuracy: 93.83%, Seleted Channel 120\n",
      "Epoch [960/1000], Overall_Loss: 1.5360, CE_Loss: 6.8414, Flops_Loss: 0.2097, Accuracy: 93.97%, Seleted Channel 120\n",
      "Epoch [970/1000], Overall_Loss: 1.5260, CE_Loss: 6.8431, Flops_Loss: 0.1967, Accuracy: 92.03%, Seleted Channel 120\n",
      "Epoch [980/1000], Overall_Loss: 1.5190, CE_Loss: 6.8068, Flops_Loss: 0.1971, Accuracy: 92.17%, Seleted Channel 120\n",
      "Epoch [990/1000], Overall_Loss: 1.5226, CE_Loss: 6.7906, Flops_Loss: 0.2056, Accuracy: 94.37%, Seleted Channel 120\n",
      "Epoch [1000/1000], Overall_Loss: 1.5124, CE_Loss: 6.7933, Flops_Loss: 0.1922, Accuracy: 79.52%, Seleted Channel 120\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the neural network\n",
    "in_dim = x_train.shape[1]\n",
    "hidden_size_choices = list(range(100,1000,10))\n",
    "num_classes =  x_train.shape[0]\n",
    "net = SuperNet(in_dim, hidden_size_choices, num_classes)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_net = optim.Adam([p for name, p in net.named_parameters() if 'arch' not in name], lr=0.0001)\n",
    "optimizer_arch = optim.Adam([p for name, p in net.named_parameters() if 'arch' in name], lr=0.01)\n",
    "\n",
    "# Search Epoch\n",
    "num_epochs = 1000\n",
    "\n",
    "# Iteartively optimize architecture parameters and network weights every 'search_freq' epochs\n",
    "search_freq = 20\n",
    "\n",
    "# The factor to balance performance (CE Loss or MSE Loss) and FLOPs\n",
    "# Larger flops_balance_factor leads to a faster network with worse performance\n",
    "flops_balance_factor = 0.8 \n",
    "\n",
    "# The tempreature is decayed by 'temp_anneal_factor' every 'temp_anneal_freq' epochs\n",
    "# Larger temp leads to a gumbel weight that is more close to 1-hot distribution  \n",
    "temp = 5\n",
    "temp_anneal_factor = 0.95\n",
    "temp_anneal_freq = num_epochs/25 # The temperatur will decay 25 times during the search\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % temp_anneal_freq == 0:\n",
    "        temp = temp * temp_anneal_factor\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, flops_loss = net(x_train, temp)\n",
    "    CE_loss = criterion(outputs, y_train)\n",
    "    loss = (1 - flops_balance_factor) * CE_loss + flops_balance_factor * flops_loss\n",
    "    \n",
    "    if int(epoch/search_freq)%2==0:\n",
    "        optimizer_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_net.step()\n",
    "    else:\n",
    "        optimizer_arch.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_arch.step()\n",
    "    \n",
    "    selected_channel_id = np.argmax(net.arch_params.data.numpy())\n",
    "    selected_channel = hidden_size_choices[selected_channel_id]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total = y_train.size(0)\n",
    "        correct = (predicted == y_train).sum().item()\n",
    "        accuracy = correct / total\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            \n",
    "            print('Epoch [{}/{}], Overall_Loss: {:.4f}, CE_Loss: {:.4f}, Flops_Loss: {:.4f}, Accuracy: {:.2f}%, Seleted Channel {}'\n",
    "                  .format(epoch+1, num_epochs, loss.item(), CE_loss.item(),\n",
    "                          flops_loss.item(), accuracy * 100, selected_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f502a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
